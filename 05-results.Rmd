# Results


```{r}
library(tidyverse)
library(patchwork)
library(GGally)
set.seed(12580)
```

## Player Attributes

There are 183978 players in this dataframe and only about 3000 rows contain NA values. Therefore, directly dropping NA variables is feasible. After that, we sample 5000 of them for a convenient plot.

```{r}
df <- read_csv('data/player_attributes.csv')
df <- df %>% drop_na()
df <- sample_n(df, 5000)
```
### Filtering goalkeepers

We firstly check the normality of each column

```{r}
df %>%
  select(!c('date', 'preferred_foot', 'attacking_work_rate', 'defensive_work_rate')) %>%
  pivot_longer(cols = !player_id, names_to = 'property', values_to = 'score') %>%
  ggplot(aes(sample = score)) +
  stat_qq() +
  stat_qq_line() +
  facet_wrap(~property)
```

We firstly notice that for features starting with the characters "gk", there is a significant deviance to normality. It is obviously because the goalkeepers are significantly better than other football players in these attributes. Since there is no information about whether one player is in charge of saving the goal. We decided to implement K-means clustering to classify them. We will not elaborate the specific ways to solve the problem since the project focuses on EDA. Before we implement this, we take a look at the histograms of "gk" features:

```{r}
gks = colnames(df)[-(1:35)]
df %>%
  select(gks) %>%
  pivot_longer(cols = everything(), names_to = 'gk', values_to = 'score') %>%
  ggplot(aes(score)) +
  geom_histogram() +
  facet_wrap(~gk)
```

It is easy to notice that for these features, there are two clusters and probably the higher score is for goalkeepers and the lower score is for other players.

```{r}
yn <- function (x){
  if(x == 1){
    result <- 'NO'
  }
  else{
    result <- 'YES'
  }
}

gk_model <- df %>% select(gks) %>% kmeans(2) 
df <- df %>% mutate(goalkeeper = gk_model$cluster - 1)
if(gk_model$centers[2, 1] > gk_model$centers[1, 1]){
  labels = c("NO", "YES")
}else{
  labels = c("YES", "NO")
}
df %>%
  select(c(gks, 'goalkeeper')) %>%
  pivot_longer(cols=!goalkeeper, names_to = 'property', values_to = 'score') %>%
  ggplot(aes(score, fill = factor(goalkeeper))) +
  geom_histogram(color = 'blue', alpha = 0.7, binwidth = 5) +
  facet_wrap(~property) +
  scale_fill_discrete(name = "goalkeeper", labels = labels)
```

We notice that except gk_kicking, all clusters clearly separated the supposed goalkeepers and other players. We surmise that there are some players who are not goalkeepers playing well in kicking. The research conducted on the types of these players will be explored later.

We can verify the justification of this clustering by simply looking at the count of goalkeepers and non-goalkeepers. In one sample, we found the total number of non-goalkeepers are 4596 and goalkeepers are 404. The ratio is 11.38. Notice that there are one goalkeeper with 10 other football players in the match so the theoretical ratio should be 10, which is close to 11.38.

### Filtering guards

We then take a look at the histograms for non-goalkeepers.

```{r}
df %>%
  filter(goalkeeper==0) %>%
  select(!c('date', 'preferred_foot', 'attacking_work_rate', 'defensive_work_rate', 'goalkeeper')) %>%
  pivot_longer(cols = !player_id, names_to = 'property', values_to = 'score') %>%
  ggplot(aes(score)) +
  geom_histogram() +
  facet_wrap(~property)
```

From the histograms, we notice that four attributes contain bimodality. Those are 'gk_kicking', 'standing_tackle', 'sliding_tackle' and 'marking'. We then make a scatter matrices for these four data. 

```{r}
df %>%
  filter(goalkeeper==0) %>%
  select(c('gk_kicking', 'standing_tackle', 'sliding_tackle', 'marking')) %>%
  ggpairs(lower = list(continuous = wrap("points", alpha = 0.3, size=0.1)), title='Bimodality Features Pairplot')
```

We realize that the last three features containing a high positive correlation. With bimodality and strong correlation, another clustering could be built. We feel that the clusters with higher score could be from the guards (or defenders). 

```{r}
ngk <- df %>% filter(goalkeeper==0) %>% subset(select=-goalkeeper)
gk <- df %>% filter(goalkeeper==1) %>% subset(select=-goalkeeper)
guard_features <- c('standing_tackle', 'sliding_tackle', 'marking')
model <- ngk %>% select(guard_features) %>% kmeans(2) 
ngk <- ngk %>% mutate(guard = model$cluster - 1)
if(model$centers[2, 1] > model$centers[1, 1]){
  guard_sign = 1
  labels = c("NO", "YES")
}else{
  guard_sign = 0
  labels = c("YES", "NO")
}
ngk %>%
  select(c(guard_features, 'guard')) %>%
  pivot_longer(cols=!guard, names_to = 'property', values_to = 'score') %>%
  ggplot(aes(score, fill = factor(guard), alpha=0.5)) +
  geom_histogram(color = 'blue', alpha = 0.5, binwidth = 5) +
  facet_wrap(~property) +
  scale_fill_discrete(name = "guard", labels = labels)
```
The clustering shows it separates guard and other players. 

We can verify the justification of this clustering by simply looking at the count of guards and non-guards. In one sample, we found the total number of non-guards are 2687 and guards are 1909. The ratio is 1.41. Notice that usually the formation of the team are "4-6" like (e.g. 4-4-2, 4-2-3-1, 4-3-3) so the theoretical ratio should be 1.5, while 1.41 is close to this ratio.

```{r}
ngk %>%
  group_by(guard) %>%
  summarize(counts = n())
```

```{r}
guards <- ngk %>% filter(guard==guard_sign) %>% subset(select = -guard)
ngs <- ngk %>% filter(guard!=guard_sign) %>% subset(select = -guard)
```


### gk_kicking issue

So what happend to "gk_kicking" high score non-goalkeepers? In this part, we would like to take a simple exploration. Firstly, we categorize the players based on whether the "gk_kicking" score is higher than 18. You can see why we choose 18 based on the following plot.

```{r}
ngk %>% ggplot(aes(x=gk_kicking)) + geom_histogram(bins=50) + geom_vline(xintercept=18, color='blue')
```

Then we plot the difference between two class on other features. Boxplot is used to avoid overplotting issue and increase the computing efficiency. The result is as followed:

```{r}
tmp = ngk %>% mutate(gkk = (gk_kicking >=18))
cols = c(names(tmp %>% select_if(is.numeric)), 'gkk')
tmp %>% select(cols) %>% select(-c(player_id, gks, guard)) %>% pivot_longer(cols=!gkk, names_to = 'property', values_to = 'score') %>%
  ggplot(aes(x=gkk, y=score)) +
  geom_boxplot() +
  facet_wrap(~property)
# tmp %>%
#   select(c(guard_features, 'guard')) %>%
#   pivot_longer(cols=!guard, names_to = 'property', values_to = 'score') %>%
#   ggplot(aes(score, fill = factor(guard), alpha=0.5)) +
#   geom_histogram(color = 'blue', alpha = 0.5, binwidth = 5) +
#   facet_wrap(~property) +
#   scale_fill_discrete(name = "guard", labels = labels) 
```

It seems that there is no significant difference for other features. We also heard from other friends that this feature is trivial for non-goalkeepers. So we decide to discard this feature without further exploration.

### further exploration of goalkeeper

We implemented PCA on goalkeepers' gk features and the biplot is shown as follow:

```{r}
gkpca_part <- gk %>% select(gks) %>% prcomp(scale. = T, center = T)
biplot(gkpca_part, xlabs=rep(".", nrow(gk)))
```

We notice that there is high similarity between these tuples: ("gk_diving", "gk_reflexes") and ("gk_positioning", "gk_handling"). That means we could create a new score from these two features in the tuple via dimension reduction.

There seems no clustering but when we make a biplot for all features, a surprising thing happens:

```{r}
gkpca <- gk %>% select_if(is_numeric) %>% select(-c(player_id)) %>% prcomp(scale. = T, center = T)
biplot(gkpca, xlabs=rep(".", nrow(gk)))
```

We see that there are two clusters of data and three clusters of features are generated. Therefore, we could apply KMeans on goalkeepers to generate two clusters. 

```{r}
pca_back <- function(pca, comp = 2){
  result <- t(t(pca$x[, c(1:comp)] %*% t(pca$rotation[, c(1:comp)])) + pca$center)
}

dr_data <- data.frame(gkpca$x[,c(1:2)])
gkpca_model <- dr_data %>% kmeans(2)
dr_data <- dr_data %>% mutate(class = gkpca_model$cluster - 1)
dr_data %>%
  ggplot(aes(x = PC1, y = PC2, color = factor(class))) +
  geom_point(alpha = 0.7)
```

### further exploration of guards

```{r}
PCA <- guards %>% select_if(is_numeric) %>% select(-c(player_id, gks)) %>% prcomp(scale. = T, center = T)
biplot(PCA, xlabs=rep(".", nrow(guards)))
```

```{r}
PCA <- guards %>% select('standing_tackle', 'sliding_tackle', 'marking') %>% prcomp(scale. = T, center = T)
biplot(PCA, xlabs=rep(".", nrow(guards)))
```

### further exploration of non-guards

```{r}
PCA <- ngs %>% select_if(is_numeric) %>% select(-c(player_id, gks)) %>% prcomp(scale. = T, center = T)
biplot(PCA, xlabs=rep(".", nrow(ngs)))
```


## team biplot

```{r}
team = read_csv('data/team_attributes.csv')
m = team %>% filter(buildUpPlayDribblingClass == 'Little') %>% select(buildUpPlayDribbling) %>% drop_na() 
m = m$buildUpPlayDribbling %>% mean()
team$buildUpPlayDribbling[is.na(team$buildUpPlayDribbling)] = m
team_pca = team %>% select_if(is.numeric) %>% select(-team_id) %>% prcomp(scale. = T, center = T)
biplot(team_pca, xlabs=rep(".", nrow(team)))
```

## Combine
```{r}
predict.kmeans <- function(x, newdata){
  apply(newdata, 1, function(r) which.min(colSums((t(x$centers) - r)^2)))
}
        
player_data <- read_csv('data/player_attributes.csv') %>% drop_na()
temp_gk2 <- player_data %>% select_if(is.numeric) %>% select(-player_id)
temp_gk <- player_data %>% select(gks)
player_data <- player_data %>% mutate(goalkeeper = predict(gk_model, temp_gk))
temp_guard <- player_data %>% select(guard_features)
player_data <- player_data %>% mutate(guard = predict(model, temp_guard))
player_data <- player_data %>% mutate(goalkeeper_type = predict(gkpca_model, predict(gkpca, temp_gk2)[,c(1:2)]))
# player_data <- player_data %>% group_by(player_id) %>% summarise_all(last)
```


```{r}
match <- read_csv('data/match.csv') %>% subset(select=date:away_player_11) %>% drop_na()
```

## A Five-Factor Team Evaluation System
Even though each team has some team attributes associated, it is crucial to include all players' attributes when evaluating a team. Therefore, in this section, we attempt to aggregate player attributes into a team evaluation.
```{r}
player_attr <- read.csv("data/player_attributes.csv")
```

We encode categorical attributes into one-hot vector and then take the averages for each of attributes across the team (due to the nature that the top players in a team is much more productive than others, we will use the top 6 players in building this system). Then, we run GBDT model for all attributes to find the relationship between attributes and the outcome (whether the team wins the match or the difference between the number of goals scored), and use [SHAP value](https://www.kaggle.com/dansbecker/shap-values) to get the the ranking of feature importance. SHAP values interpret the impact of having a certain value for a given feature in comparison to the prediction we'd make if that feature took some baseline value. See this [Github repo](https://github.com/serendipitylee/SoccerGambling) for more information.

Following the introduced procedure, we then select the top 20 importance attributes for further analysis, which are ``overall_rating``, ``potential``, ``ball_control``, ``dribbling``, ``agility``, ``sprint_speed``, ``short_passing``, ``long_passing``, ``vision``, ``crossing``, ``volleys``, ``curve``, ``finishing``, ``standing_tackle``, ``sliding_tackle``, ``marking``, ``interceptions``, ``stamina``, ``positioning`` and ``reactions``.

To build a simpler and more explainable team evaluation system, we want to reduce our 20 picked attributes to only a few variables. We can first examine the correlation between each pair of attributes to get a sense of how similar between a pair of attributes.

```{r}
corr <- cor(player_attr %>%
              drop_na() %>%
          select(overall_rating, potential, ball_control, dribbling, agility, sprint_speed, short_passing, long_passing, vision, crossing, volleys, curve, finishing, standing_tackle, sliding_tackle, marking, interceptions, stamina, positioning,  reactions))

melted_cormat <- reshape2::melt(corr)
names(melted_cormat) <- c("Var1", "Var2", "correlation")
```



```{r}
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=correlation)) +
  geom_tile() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  scale_fill_gradient(low = "white", high = "red") +
  coord_equal() +
  labs(title = "Correlation Between Picked Attributes", x = "attributes", y = "attributes")
```

In a correlation heatmap, each block represents the correlation of two attributes. The darker the color, the stronger the correlation. From the above plot, we can observe some big block with similar degree of the color which reveals that those attributes share similar information and we can further more reduce them to a lower dimension. To achieve that, we first apply clustering algorithm. See this [Github repo](https://github.com/serendipitylee/SoccerGambling) for more information.

```{r}
corr <- cor(player_attr %>%
              drop_na() %>%
          select(long_passing, curve, short_passing, crossing, overall_rating, ball_control, potential, reactions, vision, finishing, volleys, positioning, marking, sliding_tackle, standing_tackle, interceptions, dribbling, agility, sprint_speed, stamina))

melted_cormat <- reshape2::melt(corr)
names(melted_cormat) <- c("Var1", "Var2", "correlation")
```

```{r fig.height=10, fig.width=10}
par(mfrow=c(1,2))
corrplot2 <- ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=correlation)) +
  geom_tile() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  scale_fill_gradient(low = "white", high = "red") +
  coord_equal() +
  labs(title = "Correlation Between Picked Attributes\nReordered Based on Clusters", x = "attributes", y = "attributes") 
corrplot22 <- corrplot2 + 
geom_rect(mapping = aes(xmin = 0.5, xmax = 4.5, ymin = 0.5, ymax = 4.5),
          fill = NA, col = "black")  + 
geom_rect(mapping = aes(xmin = 4.5, xmax = 8.5, ymin = 4.5, ymax = 8.5),
          fill = NA, col = "black") +
geom_rect(mapping = aes(xmin = 8.5, xmax = 12.5, ymin = 8.5, ymax = 12.5),
          fill = NA, col = "black") +
geom_rect(mapping = aes(xmin = 12.5, xmax = 16.5, ymin = 12.5, ymax = 16.5),
          fill = NA, col = "black") +
geom_rect(mapping = aes(xmin = 16.5, xmax = 20.5, ymin = 16.5, ymax = 20.5),
          fill = NA, col = "black") +
  labs(title = "Correlation Between Picked Attributes\nReordered Based on Clusters\nwith Clusters Highlighted")
corrplot2+corrplot22
```
In have a better view of the cluster, we reorder the same heatmap and highlight each cluster. The final 5 clusters can be explained as following:

**Passing**: ``long_passing``, ``curve``, ``short_passing``, ``crossing``. Those attributes are all about passing.

**Overall**: ``overall_rating``, ``ball_control``, ``potential``, ``reactions``. Overall rating and potential are types of generalization, and reactions and ball controlling are important to every situation.

**Shot**: ``vision``, ``finishing``, ``volleys``, ``positioning``. It is apparent that finishing is about shots and volleys is a way to shoot. Why vision and positioning are important in getting goals? Although according to the schema visions are highly-correlated with long-passing, good vision and positioning can help with achieving goals. Let’s consider about the goals after the corner kick as an example. With brilliant vision and positioning, there is higher possibility in getting goals.

**Tackle**: ``marking``, ``sliding_tackle``, ``standing_tackle``, ``interceptions``. These attributes are about dispossess an opponent of the ball.

**Physical**: ``dribbling``, ``agility``, ``sprint_speed``, ``stamina``. Agility, sprint speed and stamina are about physical quality. And dribbling is here because perfect physical quality can lead to better dribbling ability.

We can then apply dimension reduction technique to each cluster and reduce them to a 5 index evaluation system. And each index is a combination of corresponding attributes. See this [Github repo](https://github.com/serendipitylee/SoccerGambling) for more information. The result is shown below:

Passing = 0.95 * 0.95 * long passing + 2.02 * curve + 5.50 * short passing + 1.06 * crossing

Overall = 3.54 * overall rating + 2.37 * ball control + 1.27 * potential + 1.09 * reactions

Shot = 3.89 * vision + 1.01 * finishing + 1.83 * volleys + 2.93 * positioning

Tackle = -0.70 * marking + 4.52 * sliding tackle + 1.34 * standing tackle + 5.57 * interceptions

Physical = 6.50 * dribbling + 1.11 * agility + 0.34 * sprint speed + 2.19 * stamina

Now, we can input the averages of the top 6 players in a team and learn their playing styple in the context of those 5 index, and also we can easily compare the styles and ability between teams. Playing around with the interactive plot in the next chapter to understand the system better.